# ğŸµ Moodify â€“ AI-Powered Mood-Based Music Recommendation ğŸ§

**Moodify** is an end-to-end emotion-based music recommender system that curates real-time **Spotify playlists** based on your **facial expressions**. Developed as part of the **C4 Hackathon**, this project bridges **deep learning**, **music**, and **mental wellness** through a seamless full-stack solution.

---

## ğŸš€ Features

- ğŸ” **Real-Time Emotion Detection** via webcam
- ğŸ§  **Swin-Tiny Vision Transformer** fine-tuned on **FER2013**
- ğŸ’¡ **Gemini API** integration for intelligent interaction
- ğŸ§ **Spotify SDK** to dynamically update your playlist
- âš›ï¸ **React.js Frontend** for live video input and user interaction
- ğŸŒ **Flask Backend** for model inference and API management
- ğŸ¯ Use-case Focus: Mental health support for users with **Anxiety, ADHD**, or emotional regulation needs

---

## ğŸ› ï¸ Tech Stack

| Layer       | Technology                         |
|------------|-------------------------------------|
| Frontend   | React.js                            |
| Backend    | Flask (Python)                      |
| ML Model   | Swin-Tiny Vision Transformer (ViT)  |
| Dataset    | FER2013                             |
| APIs       | Gemini API, Spotify SDK             |

---

## ğŸ§ª Demo Flow

1. **User accesses the app** â€“ camera opens via the React frontend.
2. **Facial expression captured** â€“ passed to Flask backend.
3. **Emotion inferred** â€“ using fine-tuned Swin-Tiny ViT model.
4. **Playlist updated** â€“ Spotify SDK serves a playlist matching the mood.
5. **User listens** â€“ curated songs for joy, sadness, calm, or energy.
